"""
í†µí•© í”¼ë“œë°± ìƒì„±ê¸°
- ìž…ë ¥: video_result, stt_result (ê°ê° ì˜ìƒ ë¶„ì„ JSON, STT/voice ë¶„ì„ JSON)
- ì¶œë ¥: Markdown ë³´ê³ ì„œ ë¬¸ìžì—´ê³¼ ì €ìž¥ íŒŒì¼ ê²½ë¡œ
ê¸°ì¡´ ì˜ìƒ ì „ìš©(gpt.py/feedback_generator)ê³¼ ìŒì„±/í†µí•©(feedback_api) í”„ë¡¬í”„íŠ¸ ìš”ì†Œë¥¼ í•©ì³ ë‘ íŒŒíŠ¸ë¥¼ ëª¨ë‘ ë‹¤ë£¹ë‹ˆë‹¤.
"""

import os
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

from dotenv import load_dotenv
from openai import OpenAI
from stt_processor import analyze_voice_rhythm_and_patterns

load_dotenv()

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_BASE_URL = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
OPENROUTER_MODEL = os.getenv("OPENROUTER_MODEL", "openai/gpt-4o-mini")
OPENROUTER_SITE = os.getenv("OPENROUTER_SITE_URL", "")
OPENROUTER_TITLE = os.getenv("OPENROUTER_TITLE", "combined-feedback")

_client: Optional[OpenAI] = None
if OPENROUTER_API_KEY:
    _client = OpenAI(base_url=OPENROUTER_BASE_URL, api_key=OPENROUTER_API_KEY)


def _ensure_voice_analysis(stt_result: Dict[str, Any]) -> Dict[str, Any]:
    """voice_analysisê°€ ì—†ìœ¼ë©´ ìƒì„±í•˜ì—¬ ë°˜í™˜."""
    if "voice_analysis" in stt_result:
        return stt_result
    stt_result = dict(stt_result)
    try:
        stt_result["voice_analysis"] = analyze_voice_rhythm_and_patterns(stt_result)
    except Exception as e:
        print(f"âš ï¸ voice_analysis ìƒì„± ì‹¤íŒ¨: {e}")
    return stt_result


def _build_combined_prompt(video_result: Dict[str, Any], stt_result: Dict[str, Any]) -> str:
    # Video Data
    video_meta = video_result.get("metadata", {})
    gaze = video_result.get("gaze") or {}
    posture = video_result.get("posture") or {}
    gesture = video_result.get("gesture") or {}
    hand = video_result.get("hand") or {}
    head = video_result.get("head_pose") or {}

    # Audio Data
    stt_result = _ensure_voice_analysis(stt_result)
    voice_analysis = stt_result.get("voice_analysis") or {}
    
    # Voice Metrics
    wpm = voice_analysis.get("wpm") or stt_result.get("wordsPerMinute")
    avg_pause = voice_analysis.get("avg_pause_duration") or stt_result.get("pauseDuration")
    long_pause_count = voice_analysis.get("long_pause_count")
    hesitation = voice_analysis.get("hesitation_count") or stt_result.get("hesitationCount")
    filler = voice_analysis.get("filler_count") or stt_result.get("fillerCount")
    
    summary_script = (
        stt_result.get("full_text")
        or stt_result.get("scriptRecognized")
        or stt_result.get("text_for_logic_analysis")
        or voice_analysis.get("text_for_logic_analysis")
        or ""
    )[:700]

    return f"""
    ë‹¹ì‹ ì€ ë°œí‘œ ë¶„ì„ ì „ë¬¸ê°€ì´ë©°, ì•„ëž˜ëŠ” ë°œí‘œìžì˜ ì˜ìƒ ë° ìŒì„± ë¶„ì„ ê²°ê³¼ ë°ì´í„°ìž…ë‹ˆë‹¤.
    ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì „ë¬¸ê°€ ë³´ê³ ì„œ í˜•ì‹ì˜ ë¦¬í¬íŠ¸ë¥¼ ìž‘ì„±í•˜ì„¸ìš”.

    --- ðŸ” ë¶„ì„ ë°ì´í„° ìš”ì•½ ---
    ðŸŽ¬ [ì˜ìƒ ë©”íƒ€ë°ì´í„°]
    â€¢ FPS: {video_meta.get('fps')}
    â€¢ Duration: {video_meta.get('duration_sec')}ì´ˆ
    â€¢ Resolution: {video_meta.get('resolution')}

    ðŸ‘ï¸ [ì‹œì„ (Gaze)]
    â€¢ ì •ë©´ ì‘ì‹œìœ¨(center_ratio): {gaze.get('center_ratio')}
    â€¢ ì‹œì„  ë¶„í¬(distribution): {gaze.get('distribution')}
    â€¢ í•´ì„: {gaze.get('interpretation')}

    ðŸ§ [ìžì„¸(Posture)]
    â€¢ ì•ˆì •ì„±(stability): {posture.get('stability')}
    â€¢ í‰ê·  ê¸°ìš¸ê¸°(roll_mean): {posture.get('roll_mean')}
    â€¢ í•´ì„: {posture.get('interpretation')}

    ðŸ’« [ëª¸ì§“(Gesture)]
    â€¢ ì›€ì§ìž„ ì—ë„ˆì§€(motion_energy): {gesture.get('motion_energy')}
    â€¢ í‰ê°€: {gesture.get('evaluation')}
    â€¢ í•´ì„: {gesture.get('interpretation')}

    âœ‹ [ì†ë™ìž‘(Hand)]
    â€¢ ì† ì¸ì‹ ë¹„ìœ¨(visibility_ratio): {hand.get('visibility_ratio')}
    â€¢ ì† ì›€ì§ìž„ ì •ë„(movement): {hand.get('movement')}
    â€¢ í‰ê°€: {hand.get('evaluation')}
    â€¢ í•´ì„: {hand.get('interpretation')}

    ðŸ§  [ë¨¸ë¦¬ ë°©í–¥(Head Pose)]
    â€¢ Roll í‰ê· (roll_mean): {head.get('roll_mean')}
    â€¢ Yaw í‰ê· (yaw_mean): {head.get('yaw_mean')}
    â€¢ í‰ê°€: {head.get('evaluation')}
    â€¢ í•´ì„: {head.get('interpretation')}

    ðŸŽ™ï¸ [ìŒì„±(Voice)]
    â€¢ ë§í•˜ê¸° ì†ë„(WPM): {wpm} (ê¶Œìž¥: 140~160)
    â€¢ í‰ê·  íœ´ì§€ê¸°(Pause): {avg_pause}ì´ˆ
    â€¢ ê¸´ ì¹¨ë¬µ íšŸìˆ˜: {long_pause_count}íšŒ
    â€¢ ì£¼ì €í•¨(Hesitation): {hesitation}íšŒ
    â€¢ êµ°ë”ë”ê¸° ë§(Filler): {filler}íšŒ
    â€¢ ë°œí™” ìš”ì•½: {summary_script}...

    --- ìž‘ì„± ê·œì¹™ ---
    1. **ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.**
    2. JSON êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:
       {{
         "voice_score": 0~40 ì‚¬ì´ ì •ìˆ˜,
         "video_gaze_score": 0~15 ì‚¬ì´ ì •ìˆ˜,
         "video_posture_score": 0~15 ì‚¬ì´ ì •ìˆ˜,
         "video_gesture_score": 0~10 ì‚¬ì´ ì •ìˆ˜,
         "video_score": 0~40 ì‚¬ì´ ì •ìˆ˜ (ìœ„ 3ê°œ í•©ì‚°),
         "logic_score": 20,  // (ê³ ì •ê°’)
         "content": "Markdown í˜•ì‹ì˜ ì „ì²´ ë³´ê³ ì„œ ë‚´ìš©..."
       }}
    3. **ì ìˆ˜ ì‚°ì • ê¸°ì¤€ (ì—„ê²© ì¤€ìˆ˜)**:
       - **ì˜ìƒ ì ìˆ˜ (ì´ 40ì  ë§Œì )**:
         - ì‹œì„  ì²˜ë¦¬ (Gaze): ìµœëŒ€ 15ì 
         - ìžì„¸ ì•ˆì •ì„± (Posture): ìµœëŒ€ 15ì 
         - ëª¸ì§“/ì†ë™ìž‘ (Gesture): ìµœëŒ€ 10ì 
         - *ìœ„ 3ê°œ í•­ëª©ì˜ í•©ê³„ë¥¼ `video_score`ë¡œ ê¸°ìž…í•˜ì„¸ìš”.*
       - **ìŒì„± ì ìˆ˜ (ì´ 40ì  ë§Œì )**:
         - ë§í•˜ê¸° ì†ë„, ë°œìŒ, íœ´ì§€ê¸°, ìœ ì°½ì„±ì„ ì¢…í•©í•˜ì—¬ í‰ê°€.
    4. `content` í•„ë“œ ë‚´ë¶€ì—ëŠ” ì•„ëž˜ ì„¹ì…˜ ìˆœì„œë¡œ Markdown ë³´ê³ ì„œë¥¼ ìž‘ì„±í•˜ì„¸ìš”:
       ðŸŽ¬ ì˜ìƒ ê¸°ë³¸ ì •ë³´ â†’ ðŸ‘ï¸ ì‹œì„  ë¶„ì„ â†’ ðŸ§ ìžì„¸ ë¶„ì„ â†’ ðŸ’« ëª¸ì§“/ì†ë™ìž‘ â†’ ðŸŽ™ï¸ ìŒì„±/ì „ë‹¬ë ¥ â†’ ðŸ“Š ì¢…í•© í‰ê°€í‘œ â†’ ðŸ’¬ ì´í‰ ë° ê°œì„ ì 
    5. **ì¢…í•© í‰ê°€í‘œ ìž‘ì„± ì‹œ ë°˜ë“œì‹œ ì•„ëž˜ í‘œ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš” (Regex íŒŒì‹±ìš©):**
       | í•­ëª© | ì ìˆ˜ | ê¸°ì¤€ | í‰ê°€ ìˆ˜ì¤€ |
       |---|---|---|---|
       | ì˜ìƒ(ì‹œì„ ) | OO | 0~15 | ... |
       | ì˜ìƒ(ìžì„¸) | OO | 0~15 | ... |
       | ì˜ìƒ(ëª¸ì§“) | OO | 0~10 | ... |
       | ìŒì„± | OO | 0~40 | ... |
       | ë…¼ë¦¬ | 20 | 0~20 | ... |
    6. ê° ì„¹ì…˜ì€ Markdown í‘œ í˜•ì‹ê³¼ ì„œìˆ ì‹ í•´ì„ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.
    7. ê° í•­ëª©ë³„ë¡œ ìˆ˜ì¹˜, ê¸°ì¤€, í‰ê°€ ìˆ˜ì¤€, ê°œì„ ì  ìš”ì•½ì„ ë°˜ë“œì‹œ ê¸°ìˆ í•˜ì„¸ìš”.
    8. ì „ë¬¸ê°€ ë³´ê³ ì„œ ì–´ì¡°ë¡œ, ë°œí‘œ ì½”ì¹­ ë¦¬í¬íŠ¸ì²˜ëŸ¼ ìž‘ì„±í•˜ì„¸ìš”.
    9. ìˆ˜ì¹˜ ê¸°ì¤€ ê·¼ê±°(ì˜ˆ: Mehrabian(1972) ë“±)ë¥¼ ì ì ˆížˆ ì¸ìš©í•˜ë©´ ì¢‹ìŠµë‹ˆë‹¤.
    """


def _extract_scores_from_markdown(md_text: str) -> Dict[str, int]:
    """Markdown í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ì ìˆ˜ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (Fallback)."""
    import re
    scores = {
        "voice": 0, 
        "video": 0, 
        "logic": 20,
        "video_gaze": 0,
        "video_posture": 0,
        "video_gesture": 0
    }
    
    # ì˜ˆ: | ìŒì„± | 36 | ...
    voice_pattern = re.search(r"\|\s*ìŒì„±(?: ì ìˆ˜)?\s*\|\s*(\d+)", md_text)
    if voice_pattern:
        try:
            scores["voice"] = int(voice_pattern.group(1))
        except:
            pass

    # ì„¸ë¶€ í•­ëª© ì¶”ì¶œ
    gaze_pattern = re.search(r"\|\s*ì˜ìƒ\(?ì‹œì„ \)?\s*\|\s*(\d+)", md_text)
    posture_pattern = re.search(r"\|\s*ì˜ìƒ\(?ìžì„¸\)?\s*\|\s*(\d+)", md_text)
    gesture_pattern = re.search(r"\|\s*ì˜ìƒ\(?ëª¸ì§“\)?\s*\|\s*(\d+)", md_text)

    if gaze_pattern:
        scores["video_gaze"] = int(gaze_pattern.group(1))
    if posture_pattern:
        scores["video_posture"] = int(posture_pattern.group(1))
    if gesture_pattern:
        scores["video_gesture"] = int(gesture_pattern.group(1))
        
    # í•©ì‚°
    scores["video"] = scores["video_gaze"] + scores["video_posture"] + scores["video_gesture"]
    
    # ë§Œì•½ í•©ì‚°ì´ 0ì¸ë° 'ì˜ìƒ' ì´ì ì´ ë”°ë¡œ ìžˆë‹¤ë©´?
    if scores["video"] == 0:
        video_total_pattern = re.search(r"\|\s*ì˜ìƒ(?: ì ìˆ˜)?\s*\|\s*(\d+)", md_text)
        if video_total_pattern:
             scores["video"] = int(video_total_pattern.group(1))

    return scores


def generate_combined_feedback_report(
    video_result: Dict[str, Any],
    stt_result: Dict[str, Any],
    output_name: Optional[str] = None,
    user_id: Optional[str] = None,
    run_id: Optional[str] = None,
    original_filename: Optional[str] = None,
) -> Dict[str, Any]:
    """ì˜ìƒ+ìŒì„± í†µí•© LLM ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ìž¥ (ì ìˆ˜ í¬í•¨)."""
    if not _client:
        raise RuntimeError("OPENROUTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    stt_result = _ensure_voice_analysis(stt_result)
    prompt = _build_combined_prompt(video_result, stt_result)

    completion = _client.chat.completions.create(
        model=OPENROUTER_MODEL,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë°œí‘œ ì˜ìƒ+ìŒì„± í”¼ë“œë°±ì„ ìž‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."},
            {"role": "user", "content": prompt},
        ],
        extra_headers={
            "HTTP-Referer": OPENROUTER_SITE,
            "X-Title": OPENROUTER_TITLE,
        },
    )

    raw_response = completion.choices[0].message.content
    
    # ê¸°ë³¸ê°’
    voice_score = 0
    video_score = 0
    logic_score = 20
    video_gaze = 0
    video_posture = 0
    video_gesture = 0
    feedback_md = ""

    try:
        parsed_response = json.loads(raw_response)
        feedback_md = parsed_response.get("content", "")
        voice_score = parsed_response.get("voice_score", 0)
        video_score = parsed_response.get("video_score", 0)
        logic_score = parsed_response.get("logic_score", 20)
        
        video_gaze = parsed_response.get("video_gaze_score", 0)
        video_posture = parsed_response.get("video_posture_score", 0)
        video_gesture = parsed_response.get("video_gesture_score", 0)
        
    except json.JSONDecodeError:
        print("âš ï¸ LLM ì‘ë‹µì´ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. Raw textë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        feedback_md = raw_response

    # Fallback: JSON ì ìˆ˜ê°€ 0ì´ë©´ Markdownì—ì„œ ì¶”ì¶œ ì‹œë„
    if voice_score == 0 and video_score == 0:
        print("âš ï¸ JSON ì ìˆ˜ê°€ 0ìž…ë‹ˆë‹¤. Markdownì—ì„œ ì¶”ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤.")
        extracted = _extract_scores_from_markdown(feedback_md)
        if extracted["voice"] > 0:
            voice_score = extracted["voice"]
        if extracted["video"] > 0:
            video_score = extracted["video"]
            video_gaze = extracted["video_gaze"]
            video_posture = extracted["video_posture"]
            video_gesture = extracted["video_gesture"]

    output_dir = Path("feedback_reports")
    output_dir.mkdir(exist_ok=True)
    # íŒŒì¼ëª…: userIDê°€ ìžˆìœ¼ë©´ í¬í•¨, run_id/ì›ë³¸íŒŒì¼ëª…ë„ ë¶™ì—¬ ì¶”ì  ê°€ëŠ¥í•˜ë„ë¡ ì§€ì •
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = (
        output_name
        or f"full_feedback_{user_id or 'nouser'}_{run_id or ts}_{Path(original_filename or 'upload').stem}.md"
    )
    safe_name = base_name
    output_path = output_dir / safe_name
    output_path.write_text(feedback_md, encoding="utf-8")

    return {
        "message": "âœ… ì˜ìƒ+ìŒì„± í†µí•© í”¼ë“œë°± ìƒì„± ì™„ë£Œ",
        "file_path": str(output_path),
        "feedback_preview": feedback_md[:400] + ("..." if len(feedback_md) > 400 else ""),
        "content": feedback_md,
        "scores": {
            "voice": voice_score,
            "video": video_score,
            "logic": logic_score,
            "video_gaze": video_gaze,
            "video_posture": video_posture,
            "video_gesture": video_gesture,
        }
    }
