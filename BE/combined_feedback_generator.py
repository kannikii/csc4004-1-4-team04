"""
í†µí•© í”¼ë“œë°± ìƒì„±ê¸°
- ìž…ë ¥: video_result, stt_result (ê°ê° ì˜ìƒ ë¶„ì„ JSON, STT/voice ë¶„ì„ JSON)
- ì¶œë ¥: Markdown ë³´ê³ ì„œ ë¬¸ìžì—´ê³¼ ì €ìž¥ íŒŒì¼ ê²½ë¡œ
ê¸°ì¡´ ì˜ìƒ ì „ìš©(gpt.py/feedback_generator)ê³¼ ìŒì„±/í†µí•©(feedback_api) í”„ë¡¬í”„íŠ¸ ìš”ì†Œë¥¼ í•©ì³ ë‘ íŒŒíŠ¸ë¥¼ ëª¨ë‘ ë‹¤ë£¹ë‹ˆë‹¤.
"""

import os
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional

from dotenv import load_dotenv
from openai import OpenAI
from stt_processor import analyze_voice_rhythm_and_patterns

load_dotenv()

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_BASE_URL = os.getenv("OPENROUTER_BASE_URL", "https://openrouter.ai/api/v1")
OPENROUTER_MODEL = os.getenv("OPENROUTER_MODEL", "openai/gpt-4o-mini")
OPENROUTER_SITE = os.getenv("OPENROUTER_SITE_URL", "")
OPENROUTER_TITLE = os.getenv("OPENROUTER_TITLE", "combined-feedback")

_client: Optional[OpenAI] = None
if OPENROUTER_API_KEY:
    _client = OpenAI(base_url=OPENROUTER_BASE_URL, api_key=OPENROUTER_API_KEY)


def _ensure_voice_analysis(stt_result: Dict[str, Any]) -> Dict[str, Any]:
    """voice_analysisê°€ ì—†ìœ¼ë©´ ìƒì„±í•˜ì—¬ ë°˜í™˜."""
    if "voice_analysis" in stt_result:
        return stt_result
    stt_result = dict(stt_result)
    try:
        stt_result["voice_analysis"] = analyze_voice_rhythm_and_patterns(stt_result)
    except Exception as e:
        print(f"âš ï¸ voice_analysis ìƒì„± ì‹¤íŒ¨: {e}")
    return stt_result


def _build_combined_prompt(video_result: Dict[str, Any], stt_result: Dict[str, Any]) -> str:
    video_meta = video_result.get("metadata", {})
    gaze = video_result.get("gaze") or {}
    posture = video_result.get("posture") or {}
    gesture = video_result.get("gesture") or {}
    hand = video_result.get("hand") or {}
    head = video_result.get("head_pose") or {}

    stt_result = _ensure_voice_analysis(stt_result)
    voice_analysis = stt_result.get("voice_analysis") or {}
    pause_events = voice_analysis.get("pause_events") or []
    pause_example = pause_events[:5] if pause_events else []
    summary_script = (
        stt_result.get("full_text")
        or stt_result.get("scriptRecognized")
        or stt_result.get("text_for_logic_analysis")
        or voice_analysis.get("text_for_logic_analysis")
        or ""
    )[:700]

    wpm = voice_analysis.get("wpm") or stt_result.get("wordsPerMinute")
    avg_pause = voice_analysis.get("avg_pause_duration") or stt_result.get("pauseDuration")
    long_pause_count = voice_analysis.get("long_pause_count")
    hesitation = voice_analysis.get("hesitation_count") or stt_result.get("hesitationCount")
    filler = voice_analysis.get("filler_count") or stt_result.get("fillerCount")

    return (
        "You are a presentation coach. Generate a Korean Markdown report (no code fences). "
        "Split the report into two major parts: ðŸŽ™ ìŒì„±(STT) & ì „ë‹¬ / ðŸŽ¥ ë™ìž‘Â·ì˜ìƒ ë¶„ì„. "
        "Keep ê¸°ì¡´ í‰ê°€ ì²™ë„(ì‹œì„ Â·ìžì„¸Â·ëª¸ì§“Â·ì†ë™ìž‘Â·ë¨¸ë¦¬ë°©í–¥ ë“±)ëŠ” ìœ ì§€í•˜ë©´ì„œ í•„ìš”í•˜ë©´ ì„¸ë¶€ í•­ëª©ì„ ë³´ì™„í•˜ì„¸ìš”. "
        "Use concise tables with ê¸°ì¤€/í‰ê°€/ìˆ˜ì¹˜/ê°œì„ ì , then short narratives. "
        "Voice section must include: WPM, í‰ê· /ê¸´ ì •ì§€ êµ¬ê°„, pause ì˜ˆì‹œ, filler/hesitation ë¹ˆë„, ë°œí™” ëª…ë£Œë„Â·ë¦¬ë“¬Â·ì–µì–‘ í‰ê°€, ìŠ¤í¬ë¦½íŠ¸ ìš”ì•½/ëŒ€í‘œ êµ¬ì ˆ. "
        "ì¢…í•© í‰ê°€í‘œ(10ì  ë§Œì )ì™€ ì´í‰, ê°œì„  ì œì•ˆ 3ê°€ì§€ë¥¼ í¬í•¨í•˜ì„¸ìš”.\n\n"
        "Video meta:\n"
        f"{json.dumps(video_meta, ensure_ascii=False)}\n\n"
        "Video analysis blocks:\n"
        f"gaze={json.dumps(gaze, ensure_ascii=False)}\n"
        f"posture={json.dumps(posture, ensure_ascii=False)}\n"
        f"gesture={json.dumps(gesture, ensure_ascii=False)}\n"
        f"hand={json.dumps(hand, ensure_ascii=False)}\n"
        f"head_pose={json.dumps(head, ensure_ascii=False)}\n\n"
        "Voice analysis:\n"
        f"{json.dumps(voice_analysis, ensure_ascii=False)}\n"
        f"pause_examples={json.dumps(pause_example, ensure_ascii=False)}\n"
        f"wpm={wpm}, avg_pause={avg_pause}, long_pause_count={long_pause_count}, hesitation={hesitation}, filler={filler}\n"
        f"Raw STT meta: duration_sec={stt_result.get('duration_sec')}, word_count={stt_result.get('word_count')}\n"
        f"script_snippet={json.dumps(summary_script, ensure_ascii=False)}\n"
    )


def generate_combined_feedback_report(
    video_result: Dict[str, Any],
    stt_result: Dict[str, Any],
    output_name: Optional[str] = None,
    user_id: Optional[str] = None,
    run_id: Optional[str] = None,
    original_filename: Optional[str] = None,
) -> Dict[str, Any]:
    """ì˜ìƒ+ìŒì„± í†µí•© LLM ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ìž¥."""
    if not _client:
        raise RuntimeError("OPENROUTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    stt_result = _ensure_voice_analysis(stt_result)
    prompt = _build_combined_prompt(video_result, stt_result)

    completion = _client.chat.completions.create(
        model=OPENROUTER_MODEL,
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ë°œí‘œ ì˜ìƒ+ìŒì„± í”¼ë“œë°±ì„ ìž‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ìž…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ],
        extra_headers={
            "HTTP-Referer": OPENROUTER_SITE,
            "X-Title": OPENROUTER_TITLE,
        },
    )

    feedback_md = completion.choices[0].message.content

    output_dir = Path("feedback_reports")
    output_dir.mkdir(exist_ok=True)
    # íŒŒì¼ëª…: userIDê°€ ìžˆìœ¼ë©´ í¬í•¨, run_id/ì›ë³¸íŒŒì¼ëª…ë„ ë¶™ì—¬ ì¶”ì  ê°€ëŠ¥í•˜ë„ë¡ ì§€ì •
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = (
        output_name
        or f"full_feedback_{user_id or 'nouser'}_{run_id or ts}_{Path(original_filename or 'upload').stem}.md"
    )
    safe_name = base_name
    output_path = output_dir / safe_name
    output_path.write_text(feedback_md, encoding="utf-8")

    return {
        "message": "âœ… ì˜ìƒ+ìŒì„± í†µí•© í”¼ë“œë°± ìƒì„± ì™„ë£Œ",
        "file_path": str(output_path),
        "feedback_preview": feedback_md[:400] + ("..." if len(feedback_md) > 400 else ""),
        "content": feedback_md,
    }
